{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b5c0d2440b3e4995a794ded565213150",
    "deepnote_cell_type": "markdown",
    "id": "_Mql1uRoI5v5"
   },
   "source": [
    "<h1><center>Laboratorio 6: Optimización de modelos 🧪</center></h1>\n",
    "\n",
    "<center><strong>MDS7202: Laboratorio de Programación Científica para Ciencia de Datos - Primavera 2025</strong></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bfb94b9656f145ad83e81b75d218cb70",
    "deepnote_cell_type": "markdown",
    "id": "FAPGIlEAI5v8"
   },
   "source": [
    "### Cuerpo Docente:\n",
    "\n",
    "- Profesores: Diego Cortez, Gabriel Iturra\n",
    "- Auxiliares: Melanie Peña, Valentina Rojas\n",
    "- Ayudantes: Nicolás Cabello, Cristopher Urbina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b1b537fdd27c43909a49d3476ce64d91",
    "deepnote_cell_type": "markdown",
    "id": "8NozgbkZI5v9"
   },
   "source": [
    "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no serán revisados\n",
    "\n",
    "- Nombre de alumno 1: Esteban Araneda\n",
    "- Nombre de alumno 2: Ignacio Reyes\n",
    "\n",
    "\n",
    "Reglas:\n",
    "\n",
    "- **Grupos de 2 personas**\n",
    "- Fecha de entrega: Entregas Martes a las 23:59.\n",
    "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria, pero se recomienda **fuertemente** asistir.\n",
    "- <u>Prohibidas las copias</u>. Cualquier intento de copia será debidamente penalizado con el reglamento de la escuela.\n",
    "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no estén en u-cursos no serán revisados. Recuerden que el repositorio también tiene nota.\n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
    "- Pueden usar cualquier material del curso que estimen conveniente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8qWRbJkcwP9"
   },
   "source": [
    "### **Link de repositorio de GitHub:** [Repositorio grupo OVNI](https://github.com/estebanaraneda/MDS7202_OVNI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b7dbdd30ab544cb8a8afe00648a586ae",
    "deepnote_cell_type": "markdown",
    "id": "vHU9DI6wI5v9"
   },
   "source": [
    "### Temas a tratar\n",
    "\n",
    "- Predicción de demanda usando `xgboost`\n",
    "- Búsqueda del modelo óptimo de clasificación usando `optuna`\n",
    "- Uso de pipelines.\n",
    "\n",
    "\n",
    "### Reglas:\n",
    "\n",
    "- **Grupos de 2 personas**\n",
    "- Fecha de entrega: 6 días de plazo con descuento de 1 punto por día. Entregas Martes a las 23:59.\n",
    "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria, pero se recomienda fuertemente asistir.\n",
    "- <u>Prohibidas las copias</u>. Cualquier intento de copia será debidamente penalizado con el reglamento de la escuela.\n",
    "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no estén en u-cursos no serán revisados. Recuerden que el repositorio también tiene nota.\n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
    "- Pueden usar cualquier material del curso que estimen conveniente.\n",
    "\n",
    "El laboratorio deberá ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al máximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante más eficientes que los iteradores nativos sobre DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f1c73babb7f74af588a4fa6ae14829e0",
    "deepnote_cell_type": "markdown",
    "id": "U_-sNOuOI5v9"
   },
   "source": [
    "# Importamos librerias útiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "51afe4d2df42442b9e5402ffece60ead",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4957,
    "execution_start": 1699544354044,
    "id": "ekHbM85NI5v9",
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "#!pip install -qq xgboost optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost==2.0.3 in c:\\users\\esteb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\esteb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from xgboost==2.0.3) (1.25.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\esteb\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from xgboost==2.0.3) (1.11.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost==2.0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6hJXpLCSspz"
   },
   "source": [
    "# El emprendimiento de Fiu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "44d227389a734ac59189c5e0005bc68a",
    "deepnote_cell_type": "markdown",
    "id": "b0bDalAOI5v-"
   },
   "source": [
    "Tras liderar de manera exitosa la implementación de un proyecto de ciencia de datos para caracterizar los datos generados en Santiago 2023, el misterioso corpóreo **Fiu** se anima y decide levantar su propio negocio de consultoría en machine learning. Tras varias e intensas negociaciones, Fiu logra encontrar su *primera chamba*: predecir la demanda (cantidad de venta) de una famosa productora de bebidas de calibre mundial. Al ver el gran potencial y talento que usted ha demostrado en el campo de la ciencia de datos, Fiu lo contrata como data scientist para que forme parte de su nuevo emprendimiento.\n",
    "\n",
    "Para este laboratorio deben trabajar con los datos `sales.csv` subidos a u-cursos, el cual contiene una muestra de ventas de la empresa para diferentes productos en un determinado tiempo.\n",
    "\n",
    "Para comenzar, cargue el dataset señalado y visualice a través de un `.head` los atributos que posee el dataset.\n",
    "\n",
    "<i><p align=\"center\">Fiu siendo felicitado por su excelente desempeño en el proyecto de caracterización de datos</p></i>\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media-front.elmostrador.cl/2023/09/A_UNO_1506411_2440e.jpg\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "2f9c82d204b14515ad27ae07e0b77702",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 92,
    "execution_start": 1699544359006,
    "id": "QvMPOqHuI5v-",
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "city",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "lat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "long",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pop",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "shop",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "brand",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "container",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "capacity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quantity",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "da105689-96a3-4113-b7f5-4b7c9a011959",
       "rows": [
        [
         "0",
         "0",
         "31/01/12",
         "Athens",
         "37.97945",
         "23.71622",
         "672130",
         "shop_1",
         "kinder-cola",
         "glass",
         "500ml",
         "0.96",
         "13280"
        ],
        [
         "1",
         "1",
         "31/01/12",
         "Athens",
         "37.97945",
         "23.71622",
         "672130",
         "shop_1",
         "kinder-cola",
         "plastic",
         "1.5lt",
         "2.86",
         "6727"
        ],
        [
         "2",
         "2",
         "31/01/12",
         "Athens",
         "37.97945",
         "23.71622",
         "672130",
         "shop_1",
         "kinder-cola",
         "can",
         "330ml",
         "0.87",
         "9848"
        ],
        [
         "3",
         "3",
         "31/01/12",
         "Athens",
         "37.97945",
         "23.71622",
         "672130",
         "shop_1",
         "adult-cola",
         "glass",
         "500ml",
         "1.0",
         "20050"
        ],
        [
         "4",
         "4",
         "31/01/12",
         "Athens",
         "37.97945",
         "23.71622",
         "672130",
         "shop_1",
         "adult-cola",
         "can",
         "330ml",
         "0.39",
         "25696"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>pop</th>\n",
       "      <th>shop</th>\n",
       "      <th>brand</th>\n",
       "      <th>container</th>\n",
       "      <th>capacity</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31/01/12</td>\n",
       "      <td>Athens</td>\n",
       "      <td>37.97945</td>\n",
       "      <td>23.71622</td>\n",
       "      <td>672130</td>\n",
       "      <td>shop_1</td>\n",
       "      <td>kinder-cola</td>\n",
       "      <td>glass</td>\n",
       "      <td>500ml</td>\n",
       "      <td>0.96</td>\n",
       "      <td>13280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31/01/12</td>\n",
       "      <td>Athens</td>\n",
       "      <td>37.97945</td>\n",
       "      <td>23.71622</td>\n",
       "      <td>672130</td>\n",
       "      <td>shop_1</td>\n",
       "      <td>kinder-cola</td>\n",
       "      <td>plastic</td>\n",
       "      <td>1.5lt</td>\n",
       "      <td>2.86</td>\n",
       "      <td>6727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>31/01/12</td>\n",
       "      <td>Athens</td>\n",
       "      <td>37.97945</td>\n",
       "      <td>23.71622</td>\n",
       "      <td>672130</td>\n",
       "      <td>shop_1</td>\n",
       "      <td>kinder-cola</td>\n",
       "      <td>can</td>\n",
       "      <td>330ml</td>\n",
       "      <td>0.87</td>\n",
       "      <td>9848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31/01/12</td>\n",
       "      <td>Athens</td>\n",
       "      <td>37.97945</td>\n",
       "      <td>23.71622</td>\n",
       "      <td>672130</td>\n",
       "      <td>shop_1</td>\n",
       "      <td>adult-cola</td>\n",
       "      <td>glass</td>\n",
       "      <td>500ml</td>\n",
       "      <td>1.00</td>\n",
       "      <td>20050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>31/01/12</td>\n",
       "      <td>Athens</td>\n",
       "      <td>37.97945</td>\n",
       "      <td>23.71622</td>\n",
       "      <td>672130</td>\n",
       "      <td>shop_1</td>\n",
       "      <td>adult-cola</td>\n",
       "      <td>can</td>\n",
       "      <td>330ml</td>\n",
       "      <td>0.39</td>\n",
       "      <td>25696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      date    city       lat      long     pop    shop        brand  \\\n",
       "0   0  31/01/12  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n",
       "1   1  31/01/12  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n",
       "2   2  31/01/12  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n",
       "3   3  31/01/12  Athens  37.97945  23.71622  672130  shop_1   adult-cola   \n",
       "4   4  31/01/12  Athens  37.97945  23.71622  672130  shop_1   adult-cola   \n",
       "\n",
       "  container capacity  price  quantity  \n",
       "0     glass    500ml   0.96     13280  \n",
       "1   plastic    1.5lt   2.86      6727  \n",
       "2       can    330ml   0.87      9848  \n",
       "3     glass    500ml   1.00     20050  \n",
       "4       can    330ml   0.39     25696  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "df = pd.read_csv(\"sales.csv\", sep=\",\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b50db6f2cb804932ae3f9e5748a6ea61",
    "deepnote_cell_type": "markdown",
    "id": "pk4ru76pI5v_"
   },
   "source": [
    "## 1 Generando un Baseline (5 puntos)\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media.tenor.com/O-lan6TkadUAAAAC/what-i-wnna-do-after-a-baseline.gif\">\n",
    "</p>\n",
    "\n",
    "Antes de entrenar un algoritmo, usted recuerda los apuntes de su magíster en ciencia de datos y recuerda que debe seguir una serie de *buenas prácticas* para entrenar correcta y debidamente su modelo. Después de un par de vueltas, llega a las siguientes tareas:\n",
    "\n",
    "1. Separe los datos en conjuntos de train (70%), validation (20%) y test (10%). Fije una semilla para controlar la aleatoriedad. [0.5 puntos]\n",
    "2. Implemente un `FunctionTransformer` para extraer el día, mes y año de la variable `date`. Guarde estas variables en el formato categorical de pandas. [1 punto]\n",
    "3. Implemente un `ColumnTransformer` para procesar de manera adecuada los datos numéricos y categóricos. Use `OneHotEncoder` para las variables categóricas. `Nota:` Utilice el método `.set_output(transform='pandas')` para obtener un DataFrame como salida del `ColumnTransformer` [1 punto]\n",
    "4. Guarde los pasos anteriores en un `Pipeline`, dejando como último paso el regresor `DummyRegressor` para generar predicciones en base a promedios. [0.5 punto]\n",
    "5. Entrene el pipeline anterior y reporte la métrica `mean_absolute_error` sobre los datos de validación. ¿Cómo se interpreta esta métrica para el contexto del negocio? [0.5 puntos]\n",
    "6. Finalmente, vuelva a entrenar el `Pipeline` pero esta vez usando `XGBRegressor` como modelo **utilizando los parámetros por default**. ¿Cómo cambia el MAE al implementar este algoritmo? ¿Es mejor o peor que el `DummyRegressor`? [1 punto]\n",
    "7. Guarde ambos modelos en un archivo .pkl (uno cada uno) [0.5 puntos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "1482c992d9494e5582b23dbd3431dbfd",
    "deepnote_cell_type": "code",
    "id": "sfnN7HubI5v_"
   },
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "# Inserte su código acá\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos en train, validation y test\n",
    "# 0.7, 0.2, 0.1\n",
    "\n",
    "X, y = df.drop(columns=[\"quantity\"]), df[\"quantity\"]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=1/3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Implemente un `FunctionTransformer` para extraer el día, mes y año de la variable `date`.\n",
    "# Guarde estas variables en el formato categorical de pandas. [1 punto]\n",
    "\n",
    "def datetransform(df):\n",
    "    df = df.copy()\n",
    "    df[\"date\"] = df[\"date\"].str.split(\"/\")\n",
    "    df[\"day\"] = df[\"date\"].apply(lambda x: int(x[0])).astype(\"category\")\n",
    "    df[\"month\"] = df[\"date\"].apply(lambda x: int(x[1])).astype(\"category\")\n",
    "    df[\"year\"] = df[\"date\"].apply(lambda x: int(x[2]) + 2000).astype(\"category\")\n",
    "    return df.drop(columns=[\"date\"])\n",
    "\n",
    "# Creammos el transformer\n",
    "date_transformer = FunctionTransformer(datetransform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Implemente un `ColumnTransformer` para procesar de manera adecuada los datos numéricos y categóricos. \n",
    "# Use `OneHotEncoder` para las variables categóricas. `Nota:` Utilice el método `.set_output(transform='pandas')` \n",
    "# para obtener un DataFrame como salida del `ColumnTransformer` [1 punto]\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Identificamos las columnas numéricas y categóricas\n",
    "numerical_columns = [col for col in X_train.columns if pd.api.types.is_numeric_dtype(X_train[col])]\n",
    "temporal_columns = [\"day\", \"month\", \"year\"]\n",
    "old_numerical_column = [\"date\"]\n",
    "\n",
    "categorical_columns = [col for col in X_train.columns if col not in numerical_columns + old_numerical_column]\n",
    "categorical_columns += temporal_columns\n",
    "# Creamos el ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numerical_columns),\n",
    "        (\"cat\", OneHotEncoder(sparse_output=False), categorical_columns),\n",
    "    ]\n",
    ").set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Guarde los pasos anteriores en un `Pipeline`, dejando como último paso el regresor `DummyRegressor` \n",
    "# para generar predicciones en base a promedios. [0.5 punto]\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# Creamos el Pipeline\n",
    "model = Pipeline(steps=[\n",
    "    (\"date_transformer\", date_transformer),\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", DummyRegressor(strategy=\"mean\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 13298.50\n"
     ]
    }
   ],
   "source": [
    "# 5. Entrene el pipeline anterior y reporte la métrica `mean_absolute_error` sobre los datos de validación. \n",
    "# ¿Cómo se interpreta esta métrica para el contexto del negocio? [0.5 puntos]\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Entrenamos el modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizamos las predicciones\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Calculamos la métrica\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "\n",
    "# El MAE nos indica que, en promedio, nuestras predicciones se desvían del valor real en aproximadamente x unidades.\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2411.86\n"
     ]
    }
   ],
   "source": [
    "# 6. Finalmente, vuelva a entrenar el `Pipeline` pero esta vez usando `XGBRegressor` como modelo **utilizando los parámetros por default**. \n",
    "# ¿Cómo cambia el MAE al implementar este algoritmo? ¿Es mejor o peor que el `DummyRegressor`? [1 punto]\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Creamos el Pipeline\n",
    "xgb_model = Pipeline(steps=[\n",
    "    (\"date_transformer\", date_transformer),\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", XGBRegressor()),\n",
    "])\n",
    "\n",
    "# Entrenamos el modelo\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizamos las predicciones\n",
    "y_pred = xgb_model.predict(X_val)\n",
    "\n",
    "# Calculamos la métrica\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "\n",
    "# El MAE nos indica que, en promedio, nuestras predicciones se desvían del valor real en aproximadamente x unidades.\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "\n",
    "# El MAE con XGBRegressor es mejor que con DummyRegressor, lo que indica que el modelo es capaz de capturar patrones en los datos y hacer predicciones más precisas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_model.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Guarde ambos modelos en un archivo .pkl (uno cada uno) [0.5 puntos]\n",
    "import joblib\n",
    "\n",
    "joblib.dump(model, \"dummy_model.pkl\")\n",
    "joblib.dump(xgb_model, \"xgb_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7e17e46063774ec28226fe300d42ffe0",
    "deepnote_cell_type": "markdown",
    "id": "wnyMINdKI5v_"
   },
   "source": [
    "## 2. Forzando relaciones entre parámetros con XGBoost (10 puntos)\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://64.media.tumblr.com/14cc45f9610a6ee341a45fd0d68f4dde/20d11b36022bca7b-bf/s640x960/67ab1db12ff73a530f649ac455c000945d99c0d6.gif\">\n",
    "</p>\n",
    "\n",
    "Un colega aficionado a la economía le *sopla* que la demanda guarda una relación inversa con el precio del producto. Motivado para impresionar al querido corpóreo, se propone hacer uso de esta información para mejorar su modelo realizando las siguientes tareas:\n",
    "\n",
    "1. Vuelva a entrenar el `Pipeline` con `XGBRegressor`, pero esta vez forzando una relación monótona negativa entre el precio y la cantidad. Para aplicar esta restricción apóyese en la siguiente <a href = https://xgboost.readthedocs.io/en/stable/tutorials/monotonic.html>documentación</a>. [6 puntos]\n",
    "\n",
    ">Hint 1: Para implementar el constraint se le sugiere hacerlo especificando el nombre de la variable. De ser así, probablemente le sea útil **mantener el formato de pandas** antes del step de entrenamiento.\n",
    "\n",
    ">Hint 2: Puede obtener el nombre de las columnas en el paso anterior al modelo regresor mediante el método `.get_feature_names_out()`\n",
    "\n",
    "2. Luego, vuelva a reportar el `MAE` sobre el conjunto de validación. [1 puntos]\n",
    "\n",
    "3. ¿Cómo cambia el error al incluir esta relación? ¿Tenía razón su amigo? [2 puntos]\n",
    "\n",
    "4. Guarde su modelo en un archivo .pkl [1 punto]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "f469f3b572be434191d2d5c3f11b20d2",
    "deepnote_cell_type": "code",
    "id": "B7tMnkiAI5v_"
   },
   "outputs": [],
   "source": [
    "# Inserte su código acá\n",
    "\n",
    "#1. Vuelva a entrenar el `Pipeline` con `XGBRegressor`, pero esta vez forzando una relación monótona negativa entre el precio y la cantidad. \n",
    "\n",
    "#>Hint 1: Para implementar el constraint se le sugiere hacerlo especificando el nombre de la variable. \n",
    "# De ser así, probablemente le sea útil **mantener el formato de pandas** antes del step de entrenamiento.\n",
    "\n",
    "#>Hint 2: Puede obtener el nombre de las columnas en el paso anterior al modelo regresor mediante el método `.get_feature_names_out()`\n",
    "\n",
    "# Pipeline con constraint de monotonicidad\n",
    "\n",
    "monotone_constraints = {}\n",
    "feature_names = xgb_model.named_steps['preprocessor'].get_feature_names_out()\n",
    "for name in feature_names:\n",
    "    if 'num__price' in name:\n",
    "        monotone_constraints[name] = -1  # Relación negativa\n",
    "    else:\n",
    "        monotone_constraints[name] = 0   # Sin restricción\n",
    "\n",
    "xgb_model_monotone = Pipeline(steps=[\n",
    "    (\"date_transformer\", date_transformer),\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", XGBRegressor(monotone_constraints=monotone_constraints))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2502.69\n"
     ]
    }
   ],
   "source": [
    "# 2. Luego, vuelva a reportar el `MAE` sobre el conjunto de validación. [1 puntos]\n",
    "\n",
    "xgb_model_monotone.fit(X_train, y_train)\n",
    "y_pred_monotone = xgb_model_monotone.predict(X_val)\n",
    "mae_monotone = mean_absolute_error(y_val, y_pred_monotone)\n",
    "print(f\"Mean Absolute Error: {mae_monotone:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mae aumenta al incluir la relación monótona negativa, lo que indica que la restricción impuesta afecta el rendimiento del modelo. Esto sugiere que la relación entre el precio y la cantidad no es tan simple como se pensaba inicialmente, y que forzar una relación monótona puede llevar a un aumento en el error de predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_model_monotone.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Guarde su modelo en un archivo .pkl [1 punto]\n",
    "joblib.dump(xgb_model_monotone, \"xgb_model_monotone.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e59ef80ed20b4de8921f24da74e87374",
    "deepnote_cell_type": "markdown",
    "id": "5D5-tX4dI5v_"
   },
   "source": [
    "## 1.3 Optimización de Hiperparámetros con Optuna (20 puntos)\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media.tenor.com/fmNdyGN4z5kAAAAi/hacking-lucy.gif\">\n",
    "</p>\n",
    "\n",
    "Luego de presentarle sus resultados, Fiu le pregunta si es posible mejorar *aun más* su modelo. En particular, le comenta de la optimización de hiperparámetros con metodologías bayesianas a través del paquete `optuna`. Como usted es un aficionado al entrenamiento de modelos de ML, se propone implementar la descabellada idea de su jefe.\n",
    "\n",
    "A partir de la mejor configuración obtenida en la sección anterior, utilice `optuna` para optimizar sus hiperparámetros. En particular, se pide que su optimización considere lo siguiente:\n",
    "\n",
    "- Fijar una semilla en las instancias necesarias para garantizar la reproducibilidad de resultados\n",
    "- Utilice `TPESampler` como método de muestreo\n",
    "- De `XGBRegressor`, optimice los siguientes hiperparámetros:\n",
    "    - `learning_rate` buscando valores flotantes en el rango (0.001, 0.1)\n",
    "    - `n_estimators` buscando valores enteros en el rango (50, 1000)\n",
    "    - `max_depth` buscando valores enteros en el rango (3, 10)\n",
    "    - `max_leaves` buscando valores enteros en el rango (0, 100)\n",
    "    - `min_child_weight` buscando valores enteros en el rango (1, 5)\n",
    "    - `reg_alpha` buscando valores flotantes en el rango (0, 1)\n",
    "    - `reg_lambda` buscando valores flotantes en el rango (0, 1)\n",
    "- De `OneHotEncoder`, optimice el hiperparámetro `min_frequency` buscando el mejor valor flotante en el rango (0.0, 1.0)\n",
    "\n",
    "Para ello se pide los siguientes pasos:\n",
    "1. Implemente una función `objective()` que permita minimizar el `MAE` en el conjunto de validación. Use el método `.set_user_attr()` para almacenar el mejor pipeline entrenado. [10 puntos]\n",
    "2. Fije el tiempo de entrenamiento a 5 minutos. [1 punto]\n",
    "3. Optimizar el modelo y reportar el número de *trials*, el `MAE` y los mejores hiperparámetros encontrados. ¿Cómo cambian sus resultados con respecto a la sección anterior? ¿A qué se puede deber esto? [3 puntos]\n",
    "4. Explique cada hiperparámetro y su rol en el modelo. ¿Hacen sentido los rangos de optimización indicados? [5 puntos]\n",
    "5. Guardar su modelo en un archivo .pkl [1 punto]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "de5914621cc64cb0b1bacb9ff565a97e",
    "deepnote_cell_type": "code",
    "id": "kMXXi1ckI5v_"
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "# Inserte su código acá\n",
    "\n",
    "# 1. Implemente una función `objective()` que permita minimizar el `MAE` en el conjunto de validación. Use el método `.set_user_attr()` para almacenar el mejor pipeline entrenado. [10 puntos]\n",
    "# seed para reproducibilidad\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def objective(trial):\n",
    "    # Inserte su código acá\n",
    "\n",
    "    # Definimos los hiperparámetros a optimizar\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.001, 0.1)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 1000)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 10)\n",
    "    max_leaves = trial.suggest_int(\"max_leaves\", 0, 100)\n",
    "    min_child_weight = trial.suggest_int(\"min_child_weight\", 1, 5)\n",
    "    reg_alpha = trial.suggest_float(\"reg_alpha\", 0.0, 1.0)\n",
    "    reg_lambda = trial.suggest_float(\"reg_lambda\", 0.0, 1.0)\n",
    "\n",
    "    # Hiperparámetros one-hot encoder\n",
    "    min_frequency = trial.suggest_int(\"min_frequency\", 1, 10)\n",
    "\n",
    "    # Creamos el ColumnTransformer con el nuevo hiperparámetro\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", StandardScaler(), numerical_columns),\n",
    "            (\"cat\", OneHotEncoder(sparse_output=False, min_frequency=min_frequency), categorical_columns),\n",
    "        ]\n",
    "    ).set_output(transform=\"pandas\")\n",
    "\n",
    "    # Creamos el Pipeline con los nuevos hiperparámetros\n",
    "    xgb_model = Pipeline(steps=[\n",
    "        (\"date_transformer\", date_transformer),\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"regressor\", XGBRegressor(\n",
    "            learning_rate=learning_rate,\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            max_leaves=max_leaves,\n",
    "            min_child_weight=min_child_weight,\n",
    "            reg_alpha=reg_alpha,\n",
    "            reg_lambda=reg_lambda,\n",
    "            random_state=42\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    # Entrenamos el modelo\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    # Realizamos las predicciones\n",
    "    y_pred = xgb_model.predict(X_val)\n",
    "    # Calculamos la métrica\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    # Guardamos el mejor pipeline entrenado\n",
    "    trial.set_user_attr(\"best_pipeline\", xgb_model)\n",
    "    return mae\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Fije el tiempo de entrenamiento a 5 minutos. [1 punto]\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=TPESampler(seed=SEED))\n",
    "timeout=300  # 5 minutos = 300 segundos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de trials: 288\n",
      "Mejor MAE: 1996.1556574145393\n",
      "Mejores hiperparámetros: {'learning_rate': 0.06670522157565682, 'n_estimators': 972, 'max_depth': 9, 'max_leaves': 91, 'min_child_weight': 4, 'reg_alpha': 0.8482088622961949, 'reg_lambda': 0.047484468870069775, 'min_frequency': 8}\n"
     ]
    }
   ],
   "source": [
    "# 3. Optimizar el modelo y reportar el número de *trials*, el `MAE` y los mejores hiperparámetros encontrados. \n",
    "# ¿Cómo cambian sus resultados con respecto a la sección anterior? ¿A qué se puede deber esto? [3 puntos]\n",
    "\n",
    "study.optimize(objective, timeout=timeout)  # 5 minutos = 300 segundos\n",
    "print(\"Número de trials:\", len(study.trials))\n",
    "print(\"Mejor MAE:\", study.best_value)\n",
    "print(\"Mejores hiperparámetros:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo ha logrado mejorar su rendimiento, alcanzando un MAE de aproximadamente 1996. Esto sugiere que la optimización de hiperparámetros ha sido efectiva para ajustar el modelo a los datos, permitiendo capturar mejor las relaciones subyacentes y reducir el error de predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Explique cada hiperparámetro y su rol en el modelo xgboost. ¿Hacen sentido los rangos de optimización indicados? [5 puntos]\n",
    "\n",
    "- `learning_rate`: En XGBoost, el `learning_rate` (o tasa de aprendizaje) controla cuánto se ajustan los pesos de los árboles en cada iteración. Un valor más bajo significa que el modelo aprende más lentamente, pero evita saltarse posibles mínimos. Un rango de (0.001, 0.1) es adecuado para permitir un aprendizaje gradual y evitar sobreajuste.\n",
    "- `n_estimators`: Este hiperparámetro define el número de árboles que se construirán en el modelo. Un rango de (50, 1000) es razonable, ya que permite explorar desde modelos más simples hasta modelos más complejos, pero sin llegar a ser excesivamente grande, lo que podría llevar a sobreajuste.\n",
    "- `max_depth`: Controla la profundidad máxima de cada árbol. Un rango de (3, 10) es apropiado para evitar árboles demasiado profundos que puedan sobreajustar los datos, mientras que aún permite capturar relaciones complejas.\n",
    "- `max_leaves`: Este parámetro limita el número máximo de hojas en cada árbol. Un rango de (0, 100) es adecuado para controlar la complejidad del modelo, evitando árboles con demasiadas hojas que puedan sobreajustar.\n",
    "- `min_child_weight`: Este hiperparámetro especifica el peso mínimo requerido en una hoja para que se realice una división. Un rango de (1, 5) es razonable para evitar divisiones que no aporten suficiente información, ayudando a prevenir el sobreajuste.\n",
    "- `reg_alpha`: Este hiperparámetro controla la regularización L1 en el modelo. Un rango de (0, 1) es adecuado para explorar desde ninguna regularización hasta una regularización moderada, ayudando a prevenir el sobreajuste.\n",
    "- `reg_lambda`: Similar a `reg_alpha`, este hiperparámetro controla la regularización L2 en el modelo. Un rango de (0, 1) es apropiado para explorar diferentes niveles de regularización y evitar el sobreajuste.\n",
    "- `min_frequency`: En `OneHotEncoder`, el hiperparámetro `min_frequency` determina la frecuencia mínima que una categoría debe tener para ser considerada en la codificación. Un rango de (1, 10) sugiere que solo se considerarán categorías que aparezcan al menos una vez, lo cual es adecuado para evitar la creación de demasiadas columnas con categorías raras que podrían no aportar información significativa al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_xgb_model.pkl']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Guardar su modelo en un archivo .pkl [1 punto]\n",
    "best_pipeline = study.best_trial.user_attrs[\"best_pipeline\"]\n",
    "joblib.dump(best_pipeline, \"best_xgb_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5195ccfc37e044ad9453f6eb2754f631",
    "deepnote_cell_type": "markdown",
    "id": "ZglyD_QWI5wA"
   },
   "source": [
    "## 4. Optimización de Hiperparámetros con Optuna y Prunners (17 puntos)\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://i.pinimg.com/originals/90/16/f9/9016f919c2259f3d0e8fe465049638a7.gif\">\n",
    "</p>\n",
    "\n",
    "Después de optimizar el rendimiento de su modelo varias veces, Fiu le pregunta si no es posible optimizar el entrenamiento del modelo en sí mismo. Después de leer un par de post de personas de dudosa reputación en la *deepweb*, usted llega a la conclusión que puede cumplir este objetivo mediante la implementación de **Prunning**.\n",
    "\n",
    "Vuelva a optimizar los mismos hiperparámetros que la sección pasada, pero esta vez utilizando **Prunning** en la optimización. En particular, usted debe:\n",
    "\n",
    "- Responder: ¿Qué es prunning? ¿De qué forma debería impactar en el entrenamiento? [2 puntos]\n",
    "- Redefinir la función `objective()` utilizando `optuna.integration.XGBoostPruningCallback` como método de **Prunning** [10 puntos]\n",
    "- Fijar nuevamente el tiempo de entrenamiento a 5 minutos [1 punto]\n",
    "- Reportar el número de *trials*, el `MAE` y los mejores hiperparámetros encontrados. ¿Cómo cambian sus resultados con respecto a la sección anterior? ¿A qué se puede deber esto? [3 puntos]\n",
    "- Guardar su modelo en un archivo .pkl [1 punto]\n",
    "\n",
    "Nota: Si quieren silenciar los prints obtenidos en el prunning, pueden hacerlo mediante el siguiente comando:\n",
    "\n",
    "```\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "```\n",
    "\n",
    "De implementar la opción anterior, pueden especificar `show_progress_bar = True` en el método `optimize` para *más sabor*.\n",
    "\n",
    "Hint: Si quieren especificar parámetros del método .fit() del modelo a través del pipeline, pueden hacerlo por medio de la siguiente sintaxis: `pipeline.fit(stepmodelo__parametro = valor)`\n",
    "\n",
    "Hint2: Este <a href = https://stackoverflow.com/questions/40329576/sklearn-pass-fit-parameters-to-xgboost-in-pipeline>enlace</a> les puede ser de ayuda en su implementación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "5IEEZnb-cwP_"
   },
   "outputs": [],
   "source": [
    "#!pip install optuna-integration[xgboost]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Responder: ¿Qué es prunning? ¿De qué forma debería impactar en el entrenamiento? [2 puntos]\n",
    "\n",
    "Prunning es una técnica utilizada en la optimización de hiperparámetros que permite hacer early stopping de las pruebas de configuraciones de hiperparámetros que no muestran un buen rendimiento. En lugar de completar todas las iteraciones de entrenamiento para cada conjunto de hiperparámetros, prunning evalúa el rendimiento del modelo en etapas intermedias y decide si continuar o detener la prueba basada en criterios predefinidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserte su código acá\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# - Redefinir la función `objective()` utilizando `optuna.integration.XGBoostPruningCallback` como método de **Prunning** [10 puntos]\n",
    "\n",
    "from optuna.integration import XGBoostPruningCallback\n",
    "def objective(trial):\n",
    "    # Definimos los hiperparámetros a optimizar\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.001, 0.1)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 1000)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 10)\n",
    "    max_leaves = trial.suggest_int(\"max_leaves\", 0, 100)\n",
    "    min_child_weight = trial.suggest_int(\"min_child_weight\", 1, 5)\n",
    "    reg_alpha = trial.suggest_float(\"reg_alpha\", 0.0, 1.0)\n",
    "    reg_lambda = trial.suggest_float(\"reg_lambda\", 0.0, 1.0)\n",
    "\n",
    "    # Hiperparámetros one-hot encoder\n",
    "    min_frequency = trial.suggest_int(\"min_frequency\", 1, 10)\n",
    "\n",
    "    # Creamos el ColumnTransformer con el nuevo hiperparámetro\n",
    "    date_transformer = FunctionTransformer(datetransform)\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", StandardScaler(), numerical_columns),\n",
    "            (\"cat\", OneHotEncoder(sparse_output=False, min_frequency=min_frequency), categorical_columns),\n",
    "        ]\n",
    "    ).set_output(transform=\"pandas\")\n",
    "    \n",
    "    # Transformamos los datos\n",
    "    X_train_transformed = date_transformer.transform(X_train)\n",
    "    X_train_transformed = preprocessor.fit_transform(X_train_transformed)\n",
    "    X_val_transformed = date_transformer.transform(X_val)\n",
    "    X_val_transformed = preprocessor.transform(X_val_transformed)\n",
    "\n",
    "    # Modeloado\n",
    "    model = XGBRegressor(\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        max_leaves=max_leaves,\n",
    "        min_child_weight=min_child_weight,\n",
    "        reg_alpha=reg_alpha,\n",
    "        reg_lambda=reg_lambda,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # prunning\n",
    "    # Entrenamos el modelo con prunning\n",
    "    model.fit(X_train_transformed, y_train, eval_set=[(X_val_transformed, y_val)], callbacks=[XGBoostPruningCallback(trial, \"validation_0-mae\")], eval_metric=\"mae\", verbose=False)\n",
    "\n",
    "    # Realizamos las predicciones\n",
    "    y_pred = model.predict(X_val_transformed)\n",
    "    # Calculamos la métrica\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    # Guardamos el mejor pipeline entrenado\n",
    "    trial.set_user_attr(\"best_pipeline\", model)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": "eeaa967cd8f6426d8c54f276c17dce79",
    "deepnote_cell_type": "code",
    "id": "sST6Wtj5I5wA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de trials: 564\n",
      "Mejor MAE: 2001.9508023073336\n",
      "Mejores hiperparámetros: {'learning_rate': 0.08564182880244181, 'n_estimators': 991, 'max_depth': 9, 'max_leaves': 96, 'min_child_weight': 3, 'reg_alpha': 0.22910912910519865, 'reg_lambda': 0.1073985101948807, 'min_frequency': 9}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\", sampler=TPESampler(seed=SEED))\n",
    "timeout=300  # 5 minutos = 300 segundos\n",
    "\n",
    "study.optimize(objective, timeout=timeout)  # 5 minutos = 300 segundos\n",
    "print(\"Número de trials:\", len(study.trials))\n",
    "print(\"Mejor MAE:\", study.best_value)\n",
    "print(\"Mejores hiperparámetros:\", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El número de trials aumenta a casi el doble durante el mismo tiempo de optimización, lo que indica que el prunning ha permitido evaluar más configuraciones de hiperparámetros en el mismo período. Aunque el MAE es ligeramente peor que sin prunning, esto puede deberse a que la configuración ya encontrada era efectiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_xgb_model_prunning.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar su modelo en un archivo .pkl [1 punto]\n",
    "best_pipeline = study.best_trial.user_attrs[\"best_pipeline\"]\n",
    "joblib.dump(best_pipeline, \"best_xgb_model_prunning.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8a081778cc704fc6bed05393a5419327",
    "deepnote_cell_type": "markdown",
    "id": "ZMiiVaCUI5wA"
   },
   "source": [
    "## 5. Visualizaciones (5 puntos)\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media.tenor.com/F-LgB1xTebEAAAAd/look-at-this-graph-nickelback.gif\">\n",
    "</p>\n",
    "\n",
    "\n",
    "Satisfecho con su trabajo, Fiu le pregunta si es posible generar visualizaciones que permitan entender el entrenamiento de su modelo.\n",
    "\n",
    "A partir del siguiente <a href = https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html#visualization>enlace</a>, genere las siguientes visualizaciones:\n",
    "\n",
    "1. Gráfico de historial de optimización [1 punto]\n",
    "2. Gráfico de coordenadas paralelas [1 punto]\n",
    "3. Gráfico de importancia de hiperparámetros [1 punto]\n",
    "\n",
    "Comente sus resultados:\n",
    "\n",
    "4. ¿Desde qué *trial* se empiezan a observar mejoras notables en sus resultados? [0.5 puntos]\n",
    "5. ¿Qué tendencias puede observar a partir del gráfico de coordenadas paralelas? [1 punto]\n",
    "6. ¿Cuáles son los hiperparámetros con mayor importancia para la optimización de su modelo? [0.5 puntos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "0e706dc9a8d946eda7a9eb1f0463c6d7",
    "deepnote_cell_type": "code",
    "id": "xjxAEENAI5wA"
   },
   "outputs": [],
   "source": [
    "# Inserte su código acá"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ac8a20f445d045a3becf1a518d410a7d",
    "deepnote_cell_type": "markdown",
    "id": "EoW32TA9I5wA"
   },
   "source": [
    "## 6. Síntesis de resultados (3 puntos)\n",
    "\n",
    "Finalmente:\n",
    "\n",
    "1. Genere una tabla resumen del MAE en el conjunto de validación obtenido en los 5 modelos entrenados desde Baseline hasta XGBoost con Constraints, Optuna y Prunning. [1 punto]\n",
    "2. Compare los resultados de la tabla y responda, ¿qué modelo obtiene el mejor rendimiento? [0.5 puntos]\n",
    "3. Cargue el mejor modelo, prediga sobre el conjunto de **test** y reporte su MAE. [0.5 puntos]\n",
    "4. ¿Existen diferencias con respecto a las métricas obtenidas en el conjunto de validación? ¿Porqué puede ocurrir esto? [1 punto]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jq5C6cDnJg9h"
   },
   "outputs": [],
   "source": [
    "# Inserte su código acá"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5c4654d12037494fbd385b4dc6bd1059",
    "deepnote_cell_type": "markdown",
    "id": "E_19tgBEI5wA"
   },
   "source": [
    "# Conclusión\n",
    "Exito!\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://i.pinimg.com/originals/55/3d/42/553d42bea9b10e0662a05aa8726fc7f4.gif\">\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "f63d38450a6b464c9bb6385cf11db4d9",
  "deepnote_persisted_session": {
   "createdAt": "2023-11-09T16:18:30.203Z"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
